{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e21e38c",
   "metadata": {},
   "source": [
    "## Streamlit Application\n",
    "In this section of the hands-on-lab, we will utilize Streamlit with Snowpark's Python client-side Dataframe API to create a visual front-end application for the Citibike operations team to consume the insights from the ML forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66099ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting include/streamlit_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile include/streamlit_app.py\n",
    "import sys, os\n",
    "sys.path.append(os.getcwd()+'/dags')\n",
    "\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowpark_connection import snowpark_connect\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil.relativedelta import *\n",
    "import calendar\n",
    "import altair as alt\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import time \n",
    "import json\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logging.getLogger().setLevel(logging.WARN)\n",
    "\n",
    "def update_forecast_table(forecast_df, stations:list, start_date, end_date):\n",
    "#     explainer_columns = [col for col in forecast_df.schema.names if 'EXP' in col]\n",
    "    explainer_columns=['EXPL_LAG_1', 'EXPL_LAG_7','EXPL_LAG_90','EXPL_LAG_365','EXPL_HOLIDAY','EXPL_PRECIP','EXPL_TEMP']\n",
    "    explainer_columns_new=['DAY', 'DAY_OF_WEEK', 'QUARTER', 'DAY_OF_YEAR','US_HOLIDAY', 'PRECIPITATION','TEMPERATURE']\n",
    "\n",
    "    cond = \"F.when\" + \".when\".join([\"(F.col('\" + c + \"') == F.col('EXPLAIN'), F.lit('\" + c + \"'))\" for c in explainer_columns])\n",
    "\n",
    "    df = forecast_df.filter((forecast_df['STATION_ID'].in_(stations)) &\n",
    "                       (F.col('DATE') >= start_date) & \n",
    "                       (F.col('DATE') <= end_date))\\\n",
    "                .select(['STATION_ID', \n",
    "                         F.to_char(F.col('DATE')).alias('DATE'), \n",
    "                         'PRED', \n",
    "                         'HOLIDAY',\n",
    "                         *explainer_columns])\\\n",
    "                .with_column('EXPLAIN', F.greatest(*explainer_columns))\\\n",
    "                .with_column('REASON', eval(cond))\\\n",
    "                .select(F.col('STATION_ID'), \n",
    "                        F.col('DATE'), \n",
    "                        F.col('PRED'), \n",
    "                        F.col('REASON'), \n",
    "                        F.col('EXPLAIN'), \n",
    "                        F.col('EXPL_LAG_1').alias('DAY'),\n",
    "                        F.col('EXPL_LAG_7').alias('DAY_OF_WEEK'),\n",
    "                        F.col('EXPL_LAG_90').alias('QUARTER'),\n",
    "                        F.col('EXPL_LAG_365').alias('DAY_OF_YEAR'),\n",
    "                        F.col('EXPL_HOLIDAY').alias('US_HOLIDAY'),\n",
    "                        F.col('EXPL_PRECIP').alias('PRECIPITATION'),\n",
    "                        F.col('EXPL_TEMP').alias('TEMPERATURE'),\n",
    "                       )\\\n",
    "                .to_pandas()\n",
    "    \n",
    "    df['REASON'] = pd.Categorical(df['REASON'])\n",
    "    df['REASON_CODE']=df['REASON'].cat.codes\n",
    "        \n",
    "    rect = alt.Chart(df).mark_rect().encode(alt.X('DATE:N'), \n",
    "                                        alt.Y('STATION_ID:N'), \n",
    "                                        alt.Color('REASON'),\n",
    "                                        tooltip=explainer_columns_new)\n",
    "    text = rect.mark_text(baseline='middle').encode(text='PRED:Q', color=alt.value('white'))\n",
    "\n",
    "    l = alt.layer(\n",
    "        rect, text\n",
    "    )\n",
    "\n",
    "    st.write(\"### Forecast\")\n",
    "    st.altair_chart(l, use_container_width=True)\n",
    "        \n",
    "    return None\n",
    "\n",
    "def update_eval_table(eval_df, stations:list):\n",
    "    df = eval_df.select('STATION_ID', F.to_char(F.col('RUN_DATE')).alias('RUN_DATE'), 'RMSE')\\\n",
    "                .filter(eval_df['STATION_ID'].in_(stations))\\\n",
    "                .to_pandas()\n",
    "\n",
    "    data = df.pivot(index=\"RUN_DATE\", columns=\"STATION_ID\", values=\"RMSE\")\n",
    "    data = data.reset_index().melt('RUN_DATE', var_name='STATION_ID', value_name='RMSE')\n",
    "\n",
    "    nearest = alt.selection(type='single', nearest=True, on='mouseover',\n",
    "                            fields=['RUN_DATE'], empty='none')\n",
    "\n",
    "    line = alt.Chart(data).mark_line(interpolate='basis').encode(\n",
    "        x='RUN_DATE:N',\n",
    "        y='RMSE:Q',\n",
    "        color='STATION_ID:N'\n",
    "    )\n",
    "\n",
    "    selectors = alt.Chart(data).mark_point().encode(\n",
    "        x='RUN_DATE:N',\n",
    "        opacity=alt.value(0)\n",
    "    ).add_selection(\n",
    "        nearest\n",
    "    )\n",
    "\n",
    "    points = line.mark_point().encode(\n",
    "        opacity=alt.condition(nearest, alt.value(1), alt.value(0))\n",
    "    )\n",
    "\n",
    "    text = line.mark_text(align='left', dx=5, dy=-5).encode(\n",
    "        text=alt.condition(nearest, 'RMSE:Q', alt.value(' '))\n",
    "    )\n",
    "\n",
    "    rules = alt.Chart(data).mark_rule(color='gray').encode(\n",
    "        x='RUN_DATE:N',\n",
    "    ).transform_filter(\n",
    "        nearest\n",
    "    )\n",
    "\n",
    "    l = alt.layer(\n",
    "        line, selectors, points, rules, text\n",
    "    ).properties(\n",
    "        width=600, height=300\n",
    "    )\n",
    "    st.write(\"### Model Monitor\")\n",
    "    st.altair_chart(l, use_container_width=True)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def trigger_ingest(download_file_name, run_date):    \n",
    "    dag_url='http://localhost:8080/api/v1/dags/citibikeml_monthly_taskflow/dagRuns'\n",
    "    json_payload = {\"conf\": {\"files_to_download\": [download_file_name], \"run_date\": run_date}}\n",
    "    \n",
    "    response = requests.post(dag_url, \n",
    "                            json=json_payload,\n",
    "                            auth = HTTPBasicAuth('admin', 'admin'))\n",
    "\n",
    "    run_id = json.loads(response.text)['dag_run_id']\n",
    "    #run_id = 'manual__2022-04-07T15:02:29.166108+00:00'\n",
    "\n",
    "    state=json.loads(requests.get(dag_url+'/'+run_id, auth=HTTPBasicAuth('admin', 'admin')).text)['state']\n",
    "\n",
    "    st.snow()\n",
    "\n",
    "    with st.spinner('Ingesting file: '+download_file_name):\n",
    "        while state != 'success':\n",
    "            time.sleep(5)\n",
    "            state=json.loads(requests.get(dag_url+'/'+run_id, auth=HTTPBasicAuth('admin', 'admin')).text)['state']\n",
    "    st.success('Ingested file: '+download_file_name+' State: '+str(state))\n",
    "\n",
    "#Main Body    \n",
    "session, state_dict = snowpark_connect('./include/state.json')\n",
    "forecast_df = session.table('FLAT_FORECAST')\n",
    "eval_df = session.table('FLAT_EVAL')\n",
    "trips_df = session.table('TRIPS')\n",
    "\n",
    "st.header('Citibike Forecast Application')\n",
    "st.write('In this application we leverage deep learning models to predict the number of trips started from '+\n",
    "         'a given station each day.  After selecting the stations and time range desired the application '+\\\n",
    "         'displays not only the forecast but also explains which features of the model were most used in making '+\\\n",
    "         'the prediction. Additionally users can see the historical performance of the deep learning model to '+\\\n",
    "         'monitor predictive capabilities over time.')\n",
    "\n",
    "last_trip_date = trips_df.select(F.to_date(F.max('STARTTIME'))).collect()[0][0]\n",
    "st.write('Data provided as of '+str(last_trip_date))\n",
    "\n",
    "#Create a sidebar for input\n",
    "min_date=forecast_df.select(F.min('DATE')).collect()[0][0]\n",
    "max_date=forecast_df.select(F.max('DATE')).collect()[0][0]\n",
    "\n",
    "start_date = st.sidebar.date_input('Start Date', value=min_date, min_value=min_date, max_value=max_date)\n",
    "show_days = st.sidebar.number_input('Number of days to show', value=7, min_value=1, max_value=30)\n",
    "end_date = start_date+timedelta(days=show_days)\n",
    "\n",
    "stations_df=forecast_df.select(F.col('STATION_ID')).distinct().to_pandas()\n",
    "\n",
    "sample_stations = [\"519\", \"497\", \"435\", \"402\", \"426\", \"285\", \"293\"]\n",
    "\n",
    "stations = st.sidebar.multiselect('Choose stations', stations_df['STATION_ID'], sample_stations)\n",
    "if not stations:\n",
    "    stations = stations_df['STATION_ID']\n",
    "\n",
    "update_forecast_table(forecast_df, stations, start_date, end_date)\n",
    "\n",
    "update_eval_table(eval_df, stations)\n",
    "\n",
    "\n",
    "next_ingest = last_trip_date+relativedelta(months=+1)\n",
    "next_ingest = next_ingest.replace(day=1)       \n",
    "\n",
    "if next_ingest <= datetime.strptime(\"2016-12-01\", \"%Y-%m-%d\").date():\n",
    "    download_file_name=next_ingest.strftime('%Y%m')+'-citibike-tripdata.zip'\n",
    "else:\n",
    "    download_file_name=next_ingest.strftime('%Y%m')+'-citibike-tripdata.zip'\n",
    "    \n",
    "run_date = next_ingest+relativedelta(months=+1)\n",
    "run_date = run_date.strftime('%Y_%m_%d')\n",
    "\n",
    "st.write('Next ingest for '+str(next_ingest))\n",
    "\n",
    "st.button('Run Ingest Taskflow', on_click=trigger_ingest, args=(download_file_name, run_date))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a1566",
   "metadata": {},
   "source": [
    "If running in SageMaker Studio Lab update the domain name from the URL in your browser. \n",
    "For example if the Studio Lab URL is ht<span>tps://**yyy9xxxxxxxxxxx**.studio.us-east-2.sagemaker.aws/studiolab/default/jupyter/lab </span>\n",
    "the domain name is **yyy9xxxxxxxxxxx**. ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd15d51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait a few seconds and then click the link below to open your Streamlit application \n",
      "http://127.0.0.1:6006\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  URL: \u001b[0m\u001b[1mhttp://127.0.0.1:6006\u001b[0m\n",
      "\u001b[0m\n",
      "2022-11-25 04:10:03.140 Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"/home/studio-lab-user/sagemaker-studiolab-notebooks/sfguide-citibike-ml-snowpark-python/include/streamlit_app.py\", line 172, in <module>\n",
      "    update_forecast_table(forecast_df, stations, start_date, end_date)\n",
      "  File \"/home/studio-lab-user/sagemaker-studiolab-notebooks/sfguide-citibike-ml-snowpark-python/include/streamlit_app.py\", line 28, in update_forecast_table\n",
      "    df = forecast_df.filter((forecast_df['STATION_ID'].in_(stations)) &\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/snowflake/snowpark/column.py\", line 359, in in_\n",
      "    cols = [_to_col_if_lit(col, \"in_\") for col in cols]\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/snowflake/snowpark/column.py\", line 359, in <listcomp>\n",
      "    cols = [_to_col_if_lit(col, \"in_\") for col in cols]\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/snowflake/snowpark/column.py\", line 84, in _to_col_if_lit\n",
      "    raise TypeError(\n",
      "TypeError: 'in_' expected Column, DataFrame, Iterable or LiteralType, got: <class 'pandas.core.series.Series'>\n",
      "\n",
      "2022-11-25 04:10:18.709 Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/urllib3/connection.py\", line 174, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/urllib3/util/connection.py\", line 95, in create_connection\n",
      "    raise err\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 398, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/urllib3/connection.py\", line 239, in request\n",
      "    super(HTTPConnection, self).request(method, url, body=body, headers=headers)\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/http/client.py\", line 1256, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/http/client.py\", line 1302, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/http/client.py\", line 1251, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/http/client.py\", line 1011, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/http/client.py\", line 951, in send\n",
      "    self.connect()\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/urllib3/connection.py\", line 205, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/urllib3/connection.py\", line 186, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f3358d8a910>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/requests/adapters.py\", line 489, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/urllib3/util/retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /api/v1/dags/citibikeml_monthly_taskflow/dagRuns (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f3358d8a910>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 440, in _run_script\n",
      "    self._session_state.call_callbacks()\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/streamlit/state/session_state.py\", line 538, in call_callbacks\n",
      "    self._new_widget_state.call_callback(wid)\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/streamlit/state/session_state.py\", line 271, in call_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/studio-lab-user/sagemaker-studiolab-notebooks/sfguide-citibike-ml-snowpark-python/include/streamlit_app.py\", line 123, in trigger_ingest\n",
      "    response = requests.post(dag_url,\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/requests/api.py\", line 115, in post\n",
      "    return request(\"post\", url, data=data, json=json, **kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/requests/api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/requests/sessions.py\", line 587, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/requests/sessions.py\", line 701, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/requests/adapters.py\", line 565, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /api/v1/dags/citibikeml_monthly_taskflow/dagRuns (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f3358d8a910>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "\n",
      "2022-11-25 07:22:19.807 Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 443, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"/home/studio-lab-user/sagemaker-studiolab-notebooks/sfguide-citibike-ml-snowpark-python/include/streamlit_app.py\", line 172, in <module>\n",
      "    update_forecast_table(forecast_df, stations, start_date, end_date)\n",
      "  File \"/home/studio-lab-user/sagemaker-studiolab-notebooks/sfguide-citibike-ml-snowpark-python/include/streamlit_app.py\", line 28, in update_forecast_table\n",
      "    df = forecast_df.filter((forecast_df['STATION_ID'].in_(stations)) &\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/snowflake/snowpark/column.py\", line 359, in in_\n",
      "    cols = [_to_col_if_lit(col, \"in_\") for col in cols]\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/snowflake/snowpark/column.py\", line 359, in <listcomp>\n",
      "    cols = [_to_col_if_lit(col, \"in_\") for col in cols]\n",
      "  File \"/home/studio-lab-user/.conda/envs/snowpark_0110/lib/python3.8/site-packages/snowflake/snowpark/column.py\", line 84, in _to_col_if_lit\n",
      "    raise TypeError(\n",
      "TypeError: 'in_' expected Column, DataFrame, Iterable or LiteralType, got: <class 'pandas.core.series.Series'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "studiolab_domain = ''\n",
    "\n",
    "# launch\n",
    "if studiolab_domain:\n",
    "    studiolab_region = 'us-east-2'\n",
    "    url = f'https://{studiolab_domain}.studio.{studiolab_region}.sagemaker.aws/studiolab/default/jupyter/proxy/6006/'\n",
    "    \n",
    "else: \n",
    "    \n",
    "    url = f'http://127.0.0.1:6006'\n",
    "\n",
    "print(f'Wait a few seconds and then click the link below to open your Streamlit application \\n{url}\\n')\n",
    "\n",
    "!streamlit run --theme.base dark include/streamlit_app.py --server.port 6006 \\\n",
    "                                                          --server.address 127.0.0.1 \\\n",
    "                                                          --server.headless true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc188650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de852a53-01ab-4dd6-aab9-485fcbc541f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d7428f-5d2f-4b54-9714-09da20e858c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb4eee-1d6d-4892-8798-414637c4e656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark_0110:Python",
   "language": "python",
   "name": "conda-env-snowpark_0110-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
